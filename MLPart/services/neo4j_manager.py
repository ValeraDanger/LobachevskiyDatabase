# ============= 3. Neo4j Graph Manager =============
from typing import List, Dict

from neo4j import GraphDatabase

from services.models import SearchResult, nlp


class Neo4jGraphManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–º –∑–Ω–∞–Ω–∏–π –≤ Neo4j"""

    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self._create_constraints()

    def close(self):
        self.driver.close()

    def _create_constraints(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π"""
        with self.driver.session() as session:
            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            session.run("""
                CREATE INDEX chunk_id_index IF NOT EXISTS
                FOR (c:Chunk) ON (c.chunk_id)
            """)

            session.run("""
                CREATE INDEX entity_name_index IF NOT EXISTS
                FOR (e:Entity) ON (e.name)
            """)

            session.run("""
                CREATE FULLTEXT INDEX entity_fulltext IF NOT EXISTS
                FOR (e:Entity) ON EACH [e.name, e.type]
            """)

            print("‚úì Neo4j –∏–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã")

    def add_chunk_with_entities(self, chunk_id: str, content: str,
                                metadata: Dict, entities: List[Dict]):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —á–∞–Ω–∫–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ —Å—É—â–Ω–æ—Å—Ç—è–º–∏ –≤ –≥—Ä–∞—Ñ

        Args:
            chunk_id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —á–∞–Ω–∫–∞
            content: –¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (source, chunk_index –∏ —Ç.–¥.)
            entities: –°–ø–∏—Å–æ–∫ —Å—É—â–Ω–æ—Å—Ç–µ–π [{name, type, start, end}, ...]
        """
        with self.driver.session() as session:
            # –°–æ–∑–¥–∞—ë–º —É–∑–µ–ª —á–∞–Ω–∫–∞
            session.run("""
                MERGE (c:Chunk {chunk_id: $chunk_id})
                SET c.content = $content,
                    c.source = $source,
                    c.chunk_index = $chunk_index,
                    c.length = $length
            """, chunk_id=chunk_id, content=content,
               source=metadata.get('source', ''),
               chunk_index=metadata.get('chunk_index', 0),
               length=len(content))

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ –∏ —Å–≤—è–∑–∏
            for entity in entities:
                session.run("""
                    MERGE (e:Entity {name: $name})
                    SET e.type = $type

                    WITH e
                    MATCH (c:Chunk {chunk_id: $chunk_id})
                    MERGE (e)-[r:MENTIONED_IN]->(c)
                    SET r.position = $position
                """, name=entity['name'],
                   type=entity['type'],
                   chunk_id=chunk_id,
                   position=entity.get('start', 0))

    def add_chunk_sequence(self, chunk_ids: List[str]):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π NEXT –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ —á–∞–Ω–∫–∞–º–∏"""
        with self.driver.session() as session:
            for i in range(len(chunk_ids) - 1):
                session.run("""
                    MATCH (c1:Chunk {chunk_id: $id1})
                    MATCH (c2:Chunk {chunk_id: $id2})
                    MERGE (c1)-[:NEXT]->(c2)
                    MERGE (c2)-[:PREV]->(c1)
                """, id1=chunk_ids[i], id2=chunk_ids[i+1])

    def search_by_entities(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """
        –ü–æ–∏—Å–∫ —á–∞–Ω–∫–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π –ø–æ —Å—É—â–Ω–æ—Å—Ç—è–º

        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        2. –ò—â–µ–º —ç—Ç–∏ —Å—É—â–Ω–æ—Å—Ç–∏ –≤ –≥—Ä–∞—Ñ–µ (fuzzy match —á–µ—Ä–µ–∑ fulltext)
        3. –ù–∞—Ö–æ–¥–∏–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∏
        4. –†–∞–Ω–∂–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        doc = nlp(query)
        query_entities = [ent.text.lower() for ent in doc.ents]
        query_tokens = [token.lemma_.lower() for token in doc
                       if not token.is_stop and token.is_alpha]

        all_terms = list(set(query_entities + query_tokens[:5]))  # –¢–æ–ø-5 —Ç–æ–∫–µ–Ω–æ–≤

        if not all_terms:
            return []

        print(f"  üï∏Ô∏è  –ü–æ–∏—Å–∫ –≤ –≥—Ä–∞—Ñ–µ –ø–æ —Ç–µ—Ä–º–∏–Ω–∞–º: {all_terms}")

        with self.driver.session() as session:
            # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ fulltext –∏–Ω–¥–µ–∫—Å
            result = session.run("""
                CALL db.index.fulltext.queryNodes('entity_fulltext', $search_terms)
                YIELD node AS e, score

                MATCH (e)-[:MENTIONED_IN]->(c:Chunk)

                WITH c, SUM(score) as total_score, COUNT(DISTINCT e) as entity_count
                ORDER BY total_score DESC, entity_count DESC
                LIMIT $top_k

                RETURN c.chunk_id AS chunk_id,
                       c.content AS content,
                       total_score,
                       entity_count,
                       c.source AS source,
                       c.chunk_index AS chunk_index
            """, search_terms=' OR '.join(all_terms), top_k=top_k)

            results = []
            for record in result:
                results.append(SearchResult(
                    chunk_id=record['chunk_id'],
                    content=record['content'],
                    score=float(record['total_score']),
                    source='graph',
                    metadata={
                        'source_file': record['source'],
                        'chunk_index': record['chunk_index'],
                        'entity_count': record['entity_count']
                    }
                ))

            return results

    def clear_all(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
            print("‚úì Neo4j –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞")