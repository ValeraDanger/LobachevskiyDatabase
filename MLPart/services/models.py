# ============= –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö =============

from dataclasses import dataclass
from typing import Dict

import nltk

# spaCy –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π
import spacy

from utils.config import *

# === 1. NLP-–º–æ–¥–µ–ª–∏ ===
try:
    nltk.data.find('tokenizers/punkt')
except:
    nltk.download('punkt', quiet=True)
try:
    nlp = spacy.load("ru_core_news_sm")
except:
    import os
    os.system("python -m spacy download ru_core_news_sm")
    nlp = spacy.load("ru_core_news_sm")

print("NLTK –∏ spaCy –≥–æ—Ç–æ–≤—ã.")

import os

lock_file = os.path.join(QDRANT_PATH, '.lock')
try:
    if os.path.exists(lock_file):
        os.remove(lock_file)
        print('–£–¥–∞–ª—ë–Ω lock —Ñ–∞–π–ª: —Ä–∞–±–æ—Ç–∞ —Å QdrantDb —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞.')
except Exception as e:
    print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ lock —Ñ–∞–π–ª–∞: {e}')


@dataclass
class SearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    chunk_id: str
    content: str
    score: float
    source: str  # 'vector' –∏–ª–∏ 'graph'
    metadata: Dict

    def __repr__(self):
        source_icon = "üîç" if self.source == "vector" else "üï∏Ô∏è"
        return f"{source_icon} [{self.source.upper()}] {self.chunk_id} (score: {self.score:.3f})"
